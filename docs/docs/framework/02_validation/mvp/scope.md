---
title: スコープ・基準（Scope & Criteria）
description: astranoteのMVPタイプの選択、機能スコープの定義、成功基準とKPIの設定
pageType: doc
docType: template
phase: validation
status: in-progress

# === 生成AI向けメタデータ ===
summary: |
  astranoteのMVPスコープと成功基準を定義するドキュメント。シングル機能型MVPを
  選択し、AI翻訳品質の検証に集中する。P0機能6つ（AI翻訳、エディタ、公開機能、
  認証、翻訳品質評価UI、オンボーディングフロー）をMust Haveとし、投げ銭・
  コミュニティ等はβ版以降に先送り。AARRR指標に基づく成功基準（翻訳品質4.0/5.0
  以上、初回翻訳完了率40%以上、3話完読率30%以上）を設定。

keywords:
  - MVPタイプ
  - 機能スコープ
  - 成功基準
  - KPI
  - AARRR
  - シングル機能型
  - astranote

relatedDocs:
  prerequisite:
    - path: ./hypothesis.md
      reason: 検証すべき仮説の定義
  reference:
    - path: ./index.md
      reason: MVP開発ドキュメントの全体像
    - path: ../../08_metrics/kpi.md
      reason: KPI設計の詳細
---

## 4. MVPタイプの選択

### 4.1 選択したMVPタイプ

**[ ] コンシェルジュ型** - 手動でサービスを提供
**[ ] ペーパーモック型** - 紙やスライドを使って反応を確かめる
**[ ] ランディングページ型** - LPで需要確認
**[ ] オズの魔法使い型** - 自動化に見せて手動対応
**[x] シングル機能型** - 1つの機能に絞った実装
**[ ] その他:**

### 4.2 選択理由

シングル機能型MVPを選択した理由は以下の3点である。

1. **翻訳品質は体験しなければ評価できない**: astranoteの最重要仮説は「AI翻訳品質がラノベ読者の没入感を満たせるか」である。これはランディングページやペーパーモックでは検証不可能であり、実際に動く翻訳エンジンを読者に体験させる必要がある。
2. **コンシェルジュ型では翻訳品質のスケーラビリティを検証できない**: 人間翻訳者による手動対応では、AI翻訳特有の品質課題（文脈理解、固有名詞の一貫性等）が見えない。
3. **プロンプトエンジニアリングの反復検証が必要**: ラノベ特化の翻訳品質を実現するには、プロンプトの調整→翻訳結果の評価→改善のBuild-Measure-Learnサイクルを高速で回す必要があり、動くプロダクトが不可欠。

### 4.3 期間と予算

**開発期間:** 10〜12週間（2026-02-17 〜 2026-04-27〜5-11）

> **スケジュール修正（技術レポート指摘）:** 当初計画の8週間は、翻訳エンジン（M2）の工数を過小評価していた。プロンプトエンジニアリングのチューニングサイクル（翻訳→評価→改善）には実測値で3〜4週間が必要と判断し、M2を2週間から3〜4週間に延長する。また、MVP開発前に2週間の翻訳品質POC（事前技術スパイク）を実施するため、全体スケジュールを10〜12週間に延長する。詳細は「[翻訳品質POC](./hypothesis.md#翻訳品質poc事前技術スパイク)」セクションを参照。

**予算:** 約500,000円

| 項目 | 金額 | 備考 |
|------|------|------|
| AI翻訳API費用 | ¥50,000 | Gemini 2.0 Flash / Claude 3.5 Haiku API（開発+テスト期間。Gemini Flashメインでコスト削減） |
| インフラ費用 | ¥2,000 | Cloudflare（ほぼ全て無料枠内。ドメイン費用+予備） |
| ドメイン・SSL | ¥5,000 | astranote.app |
| Mixpanel | ¥0 | 無料プラン（月1,000 MTU） |
| テスター謝礼 | ¥150,000 | 作家30名×¥3,000（Amazonギフト券）+読者100名×¥500 |
| デザインツール | ¥5,000 | Figma（無料プラン）+ アイコン素材 |
| 予備費 | ¥288,000 | 想定外の追加コスト対応 |
| **合計** | **¥500,000** | |

**リソース:**

- 開発: 1名（フルスタックエンジニア）
- デザイン: 0.5名（UI/UXデザイン、外部パートナー or AIデザインツール活用）
- その他: プロンプトエンジニアリング（開発者兼任）、テスター管理（開発者兼任）

---

## 5. 機能スコープ

### 5.1 MVPに含める機能（Must Have）

> **スコープ修正（批判・UXレポート指摘）:** MVPの最優先目標を「翻訳品質の検証」に絞り込む。投げ銭・高度なエディタ機能はβ版以降に移動。代わりに読者フィードバック収集UI（翻訳品質評価）とオンボーディングフロー設計をMVPスコープに追加する。

| 優先度 | 機能名 | 説明 | 検証する仮説 | 工数見積 |
|--------|--------|------|--------------|----------|
| P0 | ラノベ特化AI翻訳（日→英） | Claude API / GPT-4 APIを活用し、ラノベ特有の文体（一人称、固有名詞、ルビ）に対応した日英翻訳。キャラクター名辞書、文体設定（硬め/柔らかめ）をサポート。POCで最優秀と評価されたプロンプト戦略を採用 | 仮説1: AI翻訳品質 | 3〜4週間 |
| P0 | 基本的な執筆エディタ（Markdown対応） | Markdownベースのシンプルなエディタ。章・エピソード管理、自動保存、プレビュー機能。なろう/カクヨムからのインポート機能（テキスト貼り付け） | 仮説2: 作家の利用体験 | 2週間 |
| P0 | 翻訳結果の公開機能（横書き） | 翻訳された作品をURL共有で公開可能。作品ページ（タイトル、あらすじ、章一覧）、読書ビューア（横書き・縦スクロール・フォントサイズ調整）。縦書きCSS対応はMVPスコープ外（β版以降） | 仮説3: 読者の読書体験 | 1.5週間 |
| P0 | ユーザー認証 | メールアドレス/Googleアカウントでのサインアップ・ログイン。作家/読者のロール分離 | 全仮説の前提 | 0.5週間 |
| P0 | 読者向け翻訳品質評価UI | 読者が各話を読み終えた後に翻訳品質を評価できるUI。5段階評価（星評価）＋コメント欄（任意）＋修正提案欄（任意。読者が不自然と感じた表現を指摘できる）。評価データは翻訳品質の仮説検証と、プロンプト改善に活用する | 仮説1: AI翻訳品質の継続的検証 | 1週間 |
| P0 | 作家向けオンボーディングフロー | 初回翻訳完了率40%達成のための具体的なUXフロー。(1) 登録直後に「5分で作品を翻訳してみよう」のウェルカムチュートリアル → (2) サンプルテキスト貼り付け → (3) ワンクリック翻訳デモ → (4) 翻訳結果プレビュー → (5) 「自分の作品を翻訳する」へ誘導。各ステップの離脱率をMixpanelで計測し、改善に活用する | 仮説2: 作家の初回翻訳完了率 | 1週間 |

### 5.2 MVPに含めない機能（Will Not Have）

**意図的に含めない機能:**

- 投げ銭/決済機能 — Stripe連携、作家への送金フロー
- マルチプラットフォーム同時投稿 — なろう/カクヨム/Webnovelへの自動投稿
- 読者コミュニティ機能 — コメント、フォロー、お気に入り、ランキング
- 多言語翻訳（英語以外） — 中国語、韓国語、スペイン語等への翻訳
- 高度なエディタ機能 — WYSIWYG、画像挿入、共同執筆
- 作家ダッシュボード — PV分析、読者属性分析、収益レポート
- SEO/ASO最適化 — 検索エンジン向けメタデータ最適化

**理由:**

MVPの目的は「AI翻訳品質の検証」に集中すること。決済・コミュニティ・分析等の機能は翻訳品質の仮説が検証された後に追加する。これらの機能をMVPに含めると、開発期間が3〜4倍に膨らみ、検証の焦点がぼやける。リーンキャンバスで定義した損益分岐点（ライター400名+読者2,000名）の達成は正式リリース後の目標であり、MVPフェーズでは追求しない。

### 5.3 次のイテレーションで検討する機能

- 投げ銭機能（Stripe連携、70%作家還元） — 仮説3（読者のサブスク加入）の検証後
- 読者ダッシュボード（PV、フォロワー数、読了率の可視化） — β版のデータを基に設計
- コミュニティ機能（コメント、フォロー） — 読者のエンゲージメント指標を見てから判断
- なろう/カクヨムからのワンクリックインポート — 作家のオンボーディング改善用
- 多言語翻訳（中国語、韓国語） — 英語翻訳の品質が確立された後に展開

---

## 6. 成功基準とKPI

### 6.1 定量指標

| 指標 | 現状 | 目標値 | 計測方法 | 備考 |
|------|------|--------|----------|------|
| 翻訳品質スコア | N/A（新規） | 4.0/5.0以上 | 読者アンケート（5段階評価） | 最重要指標 |
| 初回翻訳完了率 | N/A | 40%以上 | Mixpanel（登録→翻訳実行のファネル） | 作家のアクティベーション |
| 3話完読率 | N/A | 30%以上 | Mixpanel（読者の読了トラッキング） | 読者のエンゲージメント |
| 7日リテンション | N/A | 25%以上 | Mixpanel（作家のリテンション） | 継続利用の意思 |
| LP登録率 | N/A | 5%以上 | Google Analytics（LP→登録フォーム） | 需要の確認 |

**AARRR指標:**

- **Acquisition（獲得）:**
  - 指標: β版LP訪問→メール登録の転換率
  - 目標: 5%以上（LP訪問者のうち）

- **Activation（活性化）:**
  - 指標: 登録→初回翻訳完了の転換率（作家）、登録→3話完読の転換率（読者）
  - 目標: 作家40%以上、読者30%以上

- **Retention（定着）:**
  - 指標: 7日後の再訪率（作家）、翌週の再読率（読者）
  - 目標: 作家25%以上、読者20%以上

- **Revenue（収益）:**
  - 指標: 「月¥1,000を払う意思がある」と回答した作家の割合（アンケート）
  - 目標: 60%以上（MVPフェーズでは実際の課金は行わない）
  - **重要な限界と注記（技術レポート P1-7 対応）:** β版ではStripeが未実装のため、支払意思の検証はアンケートベースに限られる。「バベル効果」（口頭では払うと言うが実際には払わないバイアス）のリスクがあり、アンケート結果の60%達成は、実際の課金転換率を保証しない。正式リリース後の実課金データによる再検証が必須。アンケートWTPは参考値として扱い、意思決定の主要根拠にはしない。

- **Referral（紹介）:**
  - 指標: 翻訳作品のURLシェア数、X（Twitter）でのastranote言及数
  - 目標: β版参加者の20%以上がSNSでシェア

### 6.2 定性指標

**観察したいユーザー行動:**

- 作家が翻訳結果を見た瞬間の反応（「おお！」「すごい！」等の感嘆の声があるか）
- 作家が翻訳結果をそのまま公開するか、それとも手動で修正してから公開するか（修正箇所の特定）
- 読者がAI翻訳作品を読み始めてから離脱するまでの読書パターン（どの章で離脱するか）
- 読者がファンサブ翻訳とAI翻訳を比較した時の具体的なフィードバック
- 作家同士でastranoteについて会話しているか（自然発生的な口コミ）

### 6.3 成功/失敗の判断基準

**成功と判断する条件:**

- 翻訳品質スコアが4.0/5.0以上（読者の70%以上が「十分に読める」と評価）
- 初回翻訳完了率が40%以上（作家のアクティベーション）
- 3話完読率が30%以上（読者のエンゲージメント）
- 作家の60%以上が「月¥1,000を払う」と回答

**失敗と判断する条件:**

- 翻訳品質スコアが3.0/5.0未満（読者の過半数が「読めない」と評価）
- 初回翻訳完了率が20%未満（作家がプロダクトを使いこなせない）
- 3話完読率が10%未満（読者が離脱する）
- 作家の支払意思が30%未満

**判断のタイミング:** β版開始4週間後（2026-06-09を予定）
